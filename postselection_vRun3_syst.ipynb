{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4213965a-36f5-4afb-aa9a-f4168cbb483b",
   "metadata": {},
   "source": [
    "**Run 3 analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd081e3",
   "metadata": {},
   "source": [
    "**Framework version January 2024**\n",
    "- Log :\n",
    "    - Added systematics\n",
    "    - rescale plot wrt Nexpected \n",
    "- Planned update :\n",
    "    - simplify the code \n",
    "    - standalone code, prepare a couple of input parameters and make the code working with a single command\n",
    "    \n",
    "    \n",
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98655626-5252-41be-b111-76e638cecddf",
   "metadata": {},
   "source": [
    "**Code**\n",
    "\n",
    "Folder definition on Tier:\n",
    "- in the main folder */acagnott/* added folder 'remote_folder_name';\n",
    "- in \"Snapshots\" added the folder 'remote_subfolder_name';\n",
    "- in the subfolder through dask the snapshot will be copied with name \"snap_\"+label+\"_*.root\"\n",
    "\n",
    "\n",
    "Es: se lancio \"DataMETA_2018\", gli snapshot vengono salvati in ../acagnott/Snapshot/20231229/snap_DataMET_2018_*.root\n",
    "se viene lanciato \"QCD_2018\" viene creata la cartella /acagnott/Snapshot/20231229/snap_QCDHT_100to200_2018_*.root e così via per ogni components\n",
    "\n",
    "---> Viene usato solo il giorno in modo che tutti i sample lanciati lo stesso giorno verranno salvati nella stessa cartella con nomi diversi, visto che vengono lanciati in momenti diversi della giornata lo stesso tipo di job. Forse va modificato il formato se i singoli job iniziano a durare più di un giorno dato che viene comunque lanciato un sampel per volta (in tal caso verrebbero salvati in cartelle diverse. Si potrebbe pensare di mettere la data a mano, cioé invece di usare datetime.now() si potrebbe inserire la data manualmente per fare in modo di mettere tutti i file nella stessa folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf1ce47-e2f0-48f4-8e4b-b0fa9f1bacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "sched_port = 24163#Dask port\n",
    "nmaxpartition = 1#150\n",
    "distributed = True#False#\n",
    "do_variations = True#False#\n",
    "do_histos = True\n",
    "hist_folder = \"run2022_syst\"\n",
    "do_snapshot = False\n",
    "if do_variations : do_snapshot = False\n",
    "remote_subfolder_name = datetime.now().strftime(\"%Y%m%d\") #20231229\n",
    "\n",
    "if do_variations == True:\n",
    "    variations = [\"nominal\", \"pu\", \"jer\", \"jesTotal\"]\n",
    "else :\n",
    "    variations = [\"nominal\"]\n",
    "\n",
    "in_dataset = [\n",
    "    # \"DataMETA_2018\", \"DataMETB_2018\", \"DataMETC_2018\", \"DataMETD_2018\", \"DataSingleMuA_2018\", \"DataSingleMuB_2018\", \"DataSingleMuC_2018\", \"DataSingleMuD_2018\", \"TprimeToTZ_700_2018\", \"TprimeToTZ_1000_2018\", \"TprimeToTZ_1800_2018\", \"QCD_2018\", \"TT_2018\",\"ZJetsToNuNu_2018\", \"WJets_2018\",\n",
    "    \n",
    "    # \"QCD_2022\",\n",
    "    # \"ZJetsToNuNu_2jets_2022\", \n",
    "    # \"ZJetsToNuNu_2jets_PT40to100_2J_2022\"\n",
    "    # \"ZJetsToNuNu_2jets_PT100to200_2J_2022\",\n",
    "    # \"ZJetsToNuNu_2jets_PT200to400_2J_2022\",\n",
    "    # \"ZJetsToNuNu_2jets_PT400to600_2J_2022\",\n",
    "    # \"ZJetsToNuNu_2jets_PT600_2J_2022\",\n",
    "    # \"TT_2022\",\n",
    "    # \"WJets_2jets_2022\"\n",
    "    # \"TprimeToTZ_700_2022\", \"TprimeToTZ_1000_2022\", \"TprimeToTZ_1800_2022\"\n",
    "    # \"TprimeToTZ_800_2022\", \"TprimeToTZ_900_2022\",\"TprimeToTZ_1100_2022\", \"TprimeToTZ_1200_2022\", \"TprimeToTZ_1300_2022\", \"TprimeToTZ_1400_2022\", \n",
    "    # \"TprimeToTZ_1500_2022\", \"TprimeToTZ_1600_2022\", \n",
    "    \"TprimeToTZ_1700_2022\", \n",
    "    # \"DataJetMET_2022\"\n",
    "\n",
    "    # \"QCD_2022EE\",    \n",
    "    # \"ZJetsToNuNu_2jets_2022EE\",\n",
    "    # \"TT_2022EE\",\n",
    "    # \"WJets_2jets_2022EE\"\n",
    "    # \"TprimeToTZ_700_2022EE\", \"TprimeToTZ_1000_2022EE\", \"TprimeToTZ_1800_2022EE\",\n",
    "    # \"TprimeToTZ_800_2022EE\", \"TprimeToTZ_900_2022EE\",  \n",
    "    # \"TprimeToTZ_1100_2022EE\", \"TprimeToTZ_1200_2022EE\", \"TprimeToTZ_1300_2022EE\", \"TprimeToTZ_1400_2022EE\", \n",
    "    # \"TprimeToTZ_1500_2022EE\", \"TprimeToTZ_1600_2022EE\", \"TprimeToTZ_1700_2022EE\", \n",
    "    # \"DataJetMET_2022EE\"\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "branches = {\"PuppiMET_T1_pt_nominal\", \"PuppiMET_T1_phi_nominal\", \"MHT\", \n",
    "            \"Top_mass\", \"Top_pt\", \"Top_score\", \"Top_isolationPtJetsdR04\", \"Top_isolationPtJetsdR06\", \"Top_isolationPtJetsdR08\", \"Top_isolationPtJetsdR12\", \"Top_isolationNJetsdR04\", \"Top_isolationNJetsdR06\", \"Top_isolationNJetsdR08\", \"Top_isolationNJetsdR12\",\n",
    "            \"nVetoMuon\", \"nVetoElectron\", \"nJetBtagLoose\", \"nJetBtagMedium\", \n",
    "            \"nGoodJet\", \"nTightElectron\", \"nTightMuon\", \"MT\", \"MT_T\"\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e16aaf3-78d5-4a3c-851c-21f771dcf586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/x509up_u0 /cvmfs/grid.cern.ch/etc/grid-security/certificates/\n",
      "You are producing histograms\n",
      "local folder histos: ./results/test/\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import os\n",
    "from utils.samples import *\n",
    "from utils.variables import *\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from dask.distributed import Client\n",
    "ROOT.RDF.Experimental.Distributed.open_files_locally = False\n",
    "\n",
    "os.environ['X509_CERT_DIR'] = \"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "os.environ['X509_USER_PROXY'] = \"/tmp/x509up_u0\"\n",
    "print(os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\"))\n",
    "\n",
    "\n",
    "if distributed:\n",
    "    nfiles_max = 1000\n",
    "else:\n",
    "    nfiles_max = 1  #######\n",
    "\n",
    "# Cosa aggiungere, modificare la cartella sul tier in questo modo ../acagnott/Snapshot_rdf/*dataset_name*/*data di processamente con orario*/\n",
    "# insomma come fa crab\n",
    "\n",
    "\n",
    "if do_histos: print(\"You are producing histograms\")\n",
    "if do_snapshot: print(\"You are producing snapshot\")\n",
    "\n",
    "remote_folder_name = \"Snapshots\"\n",
    "#output histos folder\n",
    "folder = \"./results/\"+hist_folder+\"/\"\n",
    "# eos_folder = \"/eos/home-a/acagnott/DarkMatter/nosynch/\"+hist_folder\n",
    "\n",
    "if do_snapshot and remote_subfolder_name == datetime.now().strftime(\"%Y%m%d\") and distributed: \n",
    "    print(\"You are naming the tier subfolder using the current day \\n\")\n",
    "    print(\"Snapshots folder name : ~/acagnott/{}/{}\".format(remote_folder_name, remote_subfolder_name))\n",
    "elif do_snapshot and distributed:\n",
    "    print(\"You are naming the tier subfolder manually\")\n",
    "    print(\"Snapshots folder name : ~/acagnott/{}/{}\".format(remote_folder_name, remote_subfolder_name))\n",
    "elif do_snapshot:\n",
    "    print(\"You are saving snapshots in local\")\n",
    "    print(\"folder name : \" + folder)\n",
    "\n",
    "\n",
    "if do_histos : \n",
    "    print(\"local folder histos: {}\".format(folder))\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "repohisto = folder+\"plots/\"\n",
    "if not os.path.exists(repohisto):\n",
    "    os.mkdir(repohisto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efe0ba0b-23a0-4b47-96f6-4dc0917ec6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating folders on Tier\n",
    "if do_snapshot and distributed:\n",
    "    tier_main_folder = \"davs://stwebdav.pi.infn.it:8443/cms/store/user/acagnott/\"\n",
    "    os.popen(\"davix-mkdir davs://stwebdav.pi.infn.it:8443/cms/store/user/acagnott/{} -E /tmp/x509up_u0 --capath /cvmfs/cms.cern.ch/grid/etc/grid-security/certificates/\".format(remote_folder_name))\n",
    "    os.popen(\"davix-mkdir davs://stwebdav.pi.infn.it:8443/cms/store/user/acagnott/{}/{} -E /tmp/x509up_u0 --capath /cvmfs/cms.cern.ch/grid/etc/grid-security/certificates/\".format(remote_folder_name, remote_subfolder_name))\n",
    "    \n",
    "# transfer function for dask worker\n",
    "def transfer_to_tier(dask_worker):\n",
    "    import os\n",
    "    os.popen('for filename in snap_*.root; do davix-put $filename davs://stwebdav.pi.infn.it:8443/cms/store/user/acagnott/{}/{}/$filename -E ./proxy --capath /cvmfs/cms.cern.ch/grid/etc/grid-security/certificates/; done'.format(remote_folder_name, remote_subfolder_name))\n",
    "    return True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3271c9-56c5-4ee1-a501-f85177699ab8",
   "metadata": {},
   "source": [
    "- Import of utils from variables.py\n",
    "Cut (if any), Regions, Variables\n",
    "\n",
    "- syncro between in_dataset and sample_dict (from sample.py) to syncronize labels and ather featurs of the dataset (as sigma if needed)\n",
    "- import of samples_dict.json to load files list (path to reach them on tier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f446ef-90d9-46e8-ad16-8ded4fa2fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regions to book: \n",
      "  SR\n",
      "  SR0fjets\n",
      "  SRatleast1fjets\n",
      "  ResSR\n",
      "  ResSR0fjets\n",
      "  ResSRatleast1fjets\n",
      "  MixSR\n",
      "  MixSR0fjets\n",
      "  MixSRatleast1fjets\n",
      "  MerSR\n",
      "  MerSR0fjets\n",
      "  MerSRatleast1fjets\n",
      "  SRTop\n",
      "  SRTop0fjets\n",
      "  SRTopatleast1fjets\n",
      "  AH\n",
      "  SL\n",
      "  AH1lWR\n",
      "  AH0lZR\n",
      "Variables for histograms :\n",
      "['PuppiMET_pt', 'PuppiMET_phi', 'PuppiMET_T1_pt_nominal', 'PuppiMET_T1_phi_nominal', 'LeadingJetPt_pt', 'LeadingFatJetPt_pt', 'nTopMixed', 'nTopResolved', 'nJet', 'nJetBtagMedium', 'nJetBtagLoose', 'nFatJet', 'MinDelta_phi', 'HT_eventHT', 'MHT', 'PV_npvsGood', 'TopMixed_TopScore_nominal', 'TopResolved_TopScore_nominal', 'EventTopCategory', 'Top_mass', 'Top_pt', 'Top_score', 'MT_T', 'FatJet_particleNetWithMass_TvsQCD']\n",
      "Datasets to process :  ['TprimeToTZ_1700_2022']\n",
      "Dataset : TprimeToTZ_1700_2022\n",
      "# of files to process :  1\n",
      "files strings :\n",
      "  root://stormgf2.pi.infn.it//store/user/acagnott/Run3Analysis_Tprime/TprimeToTZ_1700_2022/20241026_174706/tree_hadd_0.root\n",
      "# of total events in the files to process (MC only, if Data the number is None) :  88000\n"
     ]
    }
   ],
   "source": [
    "cut = requirements # ---> see variables.py\n",
    "\n",
    "regions_def = regions # ---> see variables.py\n",
    "print(\"Regions to book: \")\n",
    "for r in regions_def.keys():\n",
    "    print(\"  \"+r)\n",
    "    \n",
    "sample_file = open(\"utils/dict_samples_2022.json\", \"rb\")\n",
    "samples = json.load(sample_file)\n",
    "sample_file.close()\n",
    "\n",
    "var = vars  # ---> variables.py\n",
    "var2d = vars2D \n",
    "\n",
    "print(\"Variables for histograms :\")\n",
    "print([v._name for v in var])\n",
    "\n",
    "datasets = []\n",
    "for in_d in in_dataset:\n",
    "    if not in_d in sample_dict.keys():\n",
    "        print(\"Check the in_dataset string... \", sample_dict.keys())\n",
    "    else : \n",
    "        datasets.append(sample_dict[in_d])\n",
    "print(\"Datasets to process : \", [d.label for d in datasets])\n",
    "\n",
    "\n",
    "chain = {}\n",
    "ntot_events = {}\n",
    "for d in datasets:\n",
    "    if hasattr(d, \"components\"):\n",
    "        samples_list = d.components\n",
    "    else:\n",
    "        samples_list = [d]\n",
    "    chain[d.label] = {}\n",
    "    ntot_events[d.label] = {}\n",
    "    for s in samples_list:\n",
    "        if distributed: \n",
    "            nfiles = len(samples[d.label][s.label]['strings'])\n",
    "            for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "                if distributed:\n",
    "                    samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"davs://stwebdav.pi.infn.it:8443/cms/\")\n",
    "                else:\n",
    "                    samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "            chain[d.label][s.label] = samples[d.label][s.label]['strings']\n",
    "        else: \n",
    "            nfiles = nfiles_max\n",
    "            for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "                if distributed: samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"davs://stwebdav.pi.infn.it:8443/cms/\")\n",
    "                else: samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "            chain[d.label][s.label] = samples[d.label][s.label]['strings'][:nfiles]\n",
    "        if not \"Data\" in s.label: ntot_events[d.label][s.label] = np.sum(samples[d.label][s.label]['ntot'][:nfiles])\n",
    "        else: ntot_events[d.label][s.label] = None\n",
    "        print(\"Dataset : \"+s.label)\n",
    "        print(\"# of files to process : \", nfiles)\n",
    "        if distributed and len(chain[d.label][s.label])>2:\n",
    "            print(\"files strings :\\n  {}\\n  {}\\n  ... \\n  {}\\n  {}\".format(chain[d.label][s.label][0], chain[d.label][s.label][1], chain[d.label][s.label][-2], chain[d.label][s.label][-1]))\n",
    "        else :\n",
    "            print(\"files strings :\\n  {}\".format(chain[d.label][s.label][0]))\n",
    "        print(\"# of total events in the files to process (MC only, if Data the number is None) : \", ntot_events[d.label][s.label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31a9be5b-2e52-431b-9709-ee1c3e639b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "end of initialization\n"
     ]
    }
   ],
   "source": [
    "# initialization of clusters\n",
    "\n",
    "# upload the proxyfile to the Dask workers to make them able to access data on the grid \n",
    "\n",
    "from distributed.diagnostics.plugin import UploadFile\n",
    "def set_proxy(dask_worker):\n",
    "    import os\n",
    "    import shutil\n",
    "    working_dir = dask_worker.local_directory\n",
    "    proxy_name = 'x509up_u0'\n",
    "    os.environ['X509_USER_PROXY'] = working_dir + '/' + proxy_name\n",
    "    os.environ['X509_CERT_DIR']=\"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "    shutil.copyfile(working_dir + '/' + proxy_name, working_dir + '/../../../proxy')    \n",
    "    os.environ['EXTRA_CLING_ARGS'] = \"-O2\"\n",
    "    return os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\")\n",
    "\n",
    "text_file = open(\"utils/postselection.h\", \"r\")\n",
    "data = text_file.read()\n",
    "def my_initialization_function():\n",
    "    print(ROOT.gInterpreter.ProcessLine(\".O\"))\n",
    "    ROOT.gInterpreter.Declare('{}'.format(data))\n",
    "    print(\"end of initialization\")\n",
    "\n",
    "# set up everything properly\n",
    "if distributed == True:\n",
    "    RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame\n",
    "    client = Client(address=\"tcp://127.0.0.1:\"+str(sched_port))\n",
    "    client.restart()\n",
    "    # client.register_worker_plugin(UploadFile(\"/tmp/x509up_u0\"))\n",
    "    client.register_plugin(UploadFile(\"/tmp/x509up_u0\"))\n",
    "    client.run(set_proxy)\n",
    "    ROOT.RDF.Experimental.Distributed.initialize(my_initialization_function)\n",
    "else:\n",
    "    RDataFrame = ROOT.RDataFrame\n",
    "    my_initialization_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "963af90a-de0c-44a7-9b64-3927c34eeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### utils ###################\n",
    "def cut_string(cut):\n",
    "    return cut.replace(\" \", \"\").replace(\"&&\",\"_\").replace(\">\",\"_g_\").replace(\".\",\"_\").replace(\"==\",\"_e_\")\n",
    "\n",
    "################### preselection ###############\n",
    "def preselection(df, btagAlg, year, EE):\n",
    "    \n",
    "    df = df.Define(\"GoodJet_idx\", \"GetGoodJet(Jet_pt_nominal, Jet_eta, Jet_jetId)\")\n",
    "    df = df.Define(\"nGoodJet\", \"nGoodJet(GoodJet_idx)\")\n",
    "    df = df.Define(\"GoodFatJet_idx\", \"GetGoodJet(FatJet_pt_nominal, FatJet_eta, FatJet_jetId)\")\n",
    "    df = df.Define(\"nGoodFatJet\", \"GoodFatJet_idx.size()\")\n",
    "    df = df.Filter(\"nGoodJet>2 || nGoodFatJet>0 \", \"jet presel\")\n",
    "\n",
    "    df = df.Redefine(\"MinDelta_phi\", \"min_DeltaPhi(PuppiMET_T1_phi_nominal, Jet_phi, GoodJet_idx)\")\n",
    "    df = df.Define(\"nTightElectron\", \"nTightElectron(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"TightElectron_idx\", \"TightElectron_idx(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"nVetoElectron\", \"nVetoElectron(Electron_pt, Electron_cutBased, Electron_eta)\")\n",
    "    df = df.Define(\"nTightMuon\", \"nTightMuon(Muon_pt, Muon_eta, Muon_tightId)\")\n",
    "    df = df.Define(\"TightMuon_idx\", \"TightMuon_idx(Muon_pt, Muon_eta, Muon_tightId)\")\n",
    "    df = df.Define(\"nVetoMuon\", \"nVetoMuon(Muon_pt, Muon_eta, Muon_looseId)\")\n",
    "    df = df.Define(\"Lepton_flavour\", \"Lepton_flavour(nTightElectron, nTightMuon)\").Define(\"Lep_pt\", \"Lepton_var(Lepton_flavour, Electron_pt, TightElectron_idx, Muon_pt, TightMuon_idx)\").Define(\"Lep_phi\", \"Lepton_var(Lepton_flavour, Electron_phi, TightElectron_idx, Muon_phi, TightMuon_idx)\")\n",
    "    df = df.Define(\"MT\", \"sqrt(2 * Lep_pt * PuppiMET_T1_pt_nominal * (1 - cos(Lep_phi - PuppiMET_T1_phi_nominal)))\")\n",
    "    \n",
    "    df = df.Define(\"LeadingJetPt_idx\", \"GetLeadingPtJet(Jet_pt_nominal)\")\n",
    "    df = df.Define(\"LeadingJetPt_pt\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_pt_nominal)\")\n",
    "    df = df.Define(\"LeadingJetPt_eta\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_eta)\")\n",
    "    df = df.Define(\"LeadingJetPt_phi\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_phi)\")\n",
    "    df = df.Define(\"LeadingJetPt_mass\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_mass_nominal)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_idx\", \"GetLeadingPtJet(FatJet_pt)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_pt\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_pt_nominal)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_eta\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_eta)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_phi\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_phi)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_mass\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_mass_nominal)\")\n",
    "    df = df.Define(\"LeadingMuonPt_idx\", \"GetLeadingPtLep(Muon_pt, Muon_eta, Muon_looseId)\")\n",
    "    df = df.Define(\"LeadingMuonPt_pt\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_pt)\")\n",
    "    df = df.Define(\"LeadingMuonPt_eta\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_eta)\")\n",
    "    df = df.Define(\"LeadingMuonPt_phi\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_phi)\")\n",
    "    df = df.Define(\"LeadingElectronPt_idx\", \"GetLeadingPtLep(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"LeadingElectronPt_pt\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_pt)\")\n",
    "    df = df.Define(\"LeadingElectronPt_eta\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_eta)\")\n",
    "    df = df.Define(\"LeadingElectronPt_phi\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_phi)\")\n",
    "    \n",
    "    df = df.Define(\"nForwardJet\", \"nForwardJet(Jet_pt_nominal, Jet_jetId, Jet_eta)\")\n",
    "    df = df.Define(\"MHT\",\"MHT(GoodJet_idx, Jet_pt_nominal, Jet_phi, Jet_eta, Jet_mass_nominal)\")\n",
    "    df = df.Define(\"JetBTagLoose_idx\", \"GetJetBTag(GoodJet_idx, \"+bTagAlg+\",\"+str(year)+\",\"+str(EE)+\", 0)\")\\\n",
    "                .Define(\"nJetBtagLoose\", \"static_cast<int>(JetBTagLoose_idx.size());\")\n",
    "    df = df.Define(\"JetBTagMedium_idx\", \"GetJetBTag(GoodJet_idx, \"+bTagAlg+\",\"+str(year)+\",\"+str(EE)+\", 1)\")\\\n",
    "                .Define(\"nJetBtagMedium\", \"static_cast<int>(JetBTagMedium_idx.size());\")\n",
    "    df = df.Redefine(\"PuppiMET_T1_pt_nominal\", \"PuppiMET_T1_pt_nominal_vec[0]\")\\\n",
    "                .Redefine(\"PuppiMET_T1_phi_nominal\", \"PuppiMET_T1_phi_nominal_vec[0]\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "############### trigger selection #####################\n",
    "def trigger_filter(df, data, isMC):\n",
    "    hlt_met = \"(HLT_PFMET120_PFMHT120_IDTight || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight)\"\n",
    "    df_trig = df.Filter(hlt_met, \"triggerMET\")\n",
    "    return df_trig\n",
    "\n",
    "############### top selection ########################\n",
    "def select_top(df, isMC):\n",
    "    # return indices of the FatJet with particleNet score over the thresholds \n",
    "    df_goodtopMer = df.Define(\"GoodTopMer_idx\", \"select_TopMer(FatJet_particleNetWithMass_TvsQCD, GoodFatJet_idx)\")\n",
    "    # return indices of the TopMixed over the threshold with any object in common\n",
    "    df_goodtopMix = df_goodtopMer.Define(\"GoodTopMix_idx\", \"select_TopMix(TopMixed_TopScore_nominal, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, GoodJet_idx, GoodFatJet_idx)\")\n",
    "    # return indices of the TopResolved over the threshold with any object in common\n",
    "    df_goodtopRes = df_goodtopMix.Define(\"GoodTopRes_idx\", \"select_TopRes(TopResolved_TopScore_nominal, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, GoodJet_idx)\")\n",
    "    \n",
    "    df_nTops = df_goodtopRes.Define(\"nGoodTopResolved\", \"nTop(GoodTopRes_idx)\")\\\n",
    "                            .Define(\"nGoodTopMixed\", \"nTop(GoodTopMix_idx)\")\\\n",
    "                            .Define(\"nGoodTopMerged\", \"nTop(GoodTopMer_idx)\")\n",
    "    \n",
    "    \n",
    "    # return:  1- Event Resolved, 2- Event Mixed, 3- Event Merged, 4- Event Nothing, ...\n",
    "    df_topcategory = df_nTops.Define(\"EventTopCategory\", \"select_TopCategory(GoodTopMer_idx, GoodTopMix_idx, GoodTopRes_idx)\")\n",
    "    if isMC:\n",
    "        df_topcategory = df_topcategory.Define(\"EventTopCategoryWithTruth\", \"select_TopCategoryWithTruth(EventTopCategory, FatJet_matched, GoodTopMer_idx, TopMixed_truth, GoodTopMix_idx, TopResolved_truth, GoodTopRes_idx)\")\n",
    "    \n",
    "    df_topselected = df_topcategory.Define(\"Top_idx\",\n",
    "                                           \"select_bestTop(EventTopCategory, FatJet_particleNetWithMass_TvsQCD, TopMixed_TopScore_nominal, TopResolved_TopScore_nominal)\")\n",
    "    # return best top idx wrt category --> the idx is referred to the list of candidates fixed by the EventTopCategory\n",
    "    df_topvariables = df_topselected.Define(\"Top_pt\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_pt_nominal, TopMixed_pt_nominal, TopResolved_pt_nominal)\")\\\n",
    "                        .Define(\"Top_eta\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_eta, TopMixed_eta, TopResolved_eta)\")\\\n",
    "                        .Define(\"Top_phi\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_phi, TopMixed_phi, TopResolved_phi)\")\\\n",
    "                        .Define(\"Top_mass\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_mass_nominal, TopMixed_mass_nominal, TopResolved_mass_nominal)\")\\\n",
    "                        .Define(\"Top_score\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_particleNetWithMass_TvsQCD, TopMixed_TopScore_nominal, TopResolved_TopScore_nominal)\")\\\n",
    "                        .Define(\"Top_isolationPtJetsdR04\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.4, 1)\")\\\n",
    "                        .Define(\"Top_isolationPtJetsdR06\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.6, 1)\")\\\n",
    "                        .Define(\"Top_isolationPtJetsdR08\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.8, 1)\")\\\n",
    "                        .Define(\"Top_isolationPtJetsdR12\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 1.2, 1)\")\\\n",
    "                        .Define(\"Top_isolationNJetsdR04\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.4, 0)\")\\\n",
    "                        .Define(\"Top_isolationNJetsdR06\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.6, 0)\")\\\n",
    "                        .Define(\"Top_isolationNJetsdR08\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 0.8, 0)\")\\\n",
    "                        .Define(\"Top_isolationNJetsdR12\",\"TopIsolation_NJets(EventTopCategory, Top_idx, TopMixed_idxFatJet, TopMixed_idxJet0, TopMixed_idxJet1, TopMixed_idxJet2, TopMixed_pt_nominal, TopMixed_phi, TopMixed_eta, TopResolved_idxJet0, TopResolved_idxJet1, TopResolved_idxJet2, TopResolved_pt_nominal, TopResolved_phi, TopResolved_eta, FatJet_pt_nominal, FatJet_eta, FatJet_phi, FatJet_jetId, Jet_pt_nominal, Jet_eta, Jet_phi, Jet_jetId, 1.2, 0)\")\n",
    "\n",
    "    if isMC:\n",
    "        df_topvariables = df_topvariables.Define(\"Top_truth\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_matched, TopMixed_truth, TopResolved_truth)\")\n",
    "    # NB: TopTruth for Merged is replaced with FatJet_matched, the variable is between 0 and 3 \n",
    "    # where 3 means true end less than 3 means false \n",
    "    return df_topvariables\n",
    "def energetic_variations(df):\n",
    "    #  Da aggiungere variazione dei fatjet\n",
    "    df_sys = df.Vary([\"Jet_pt_nominal\", \"Jet_mass_nominal\", \"FatJet_pt_nominal\", \"FatJet_mass_nominal\", \"PuppiMET_T1_pt_nominal_vec\", \"PuppiMET_T1_phi_nominal_vec\", \"TopMixed_pt_nominal\", \"TopResolved_pt_nominal\", \"TopMixed_mass_nominal\", \"TopResolved_mass_nominal\",  \"TopMixed_TopScore_nominal\", \"TopResolved_TopScore_nominal\"], \"RVec<RVec<RVec<float>>>{{Jet_pt_jerdown, Jet_pt_jerup}, {Jet_mass_jerdown, Jet_mass_jerup}, {FatJet_pt_jerdown, FatJet_pt_jerup}, {FatJet_mass_jerdown, FatJet_mass_jerup}, {PuppiMET_T1_pt_jerdown_vec, PuppiMET_T1_pt_jerup_vec}, {PuppiMET_T1_phi_jerdown_vec, PuppiMET_T1_phi_jerup_vec}, {TopMixed_pt_jerdown, TopMixed_pt_jerup}, {TopResolved_pt_jerdown, TopResolved_pt_jerup}, {TopMixed_mass_jerdown, TopMixed_mass_jerup}, {TopResolved_mass_jerdown, TopResolved_mass_jerup}, {TopMixed_TopScore_jerdown, TopMixed_TopScore_jerup}, {TopResolved_TopScore_jerdown, TopResolved_TopScore_jerup}}\", variationTags=[\"down\", \"up\"], variationName=\"jer\")\\\n",
    "               .Vary([\"Jet_pt_nominal\", \"Jet_mass_nominal\", \"FatJet_pt_nominal\", \"FatJet_mass_nominal\", \"PuppiMET_T1_pt_nominal_vec\", \"PuppiMET_T1_phi_nominal_vec\", \"TopMixed_pt_nominal\", \"TopResolved_pt_nominal\", \"TopMixed_mass_nominal\", \"TopResolved_mass_nominal\",  \"TopMixed_TopScore_nominal\", \"TopResolved_TopScore_nominal\"], \"RVec<RVec<RVec<float>>>{{Jet_pt_jesTotaldown, Jet_pt_jesTotalup}, {Jet_mass_jesTotaldown, Jet_mass_jesTotalup}, {FatJet_pt_jesTotaldown, FatJet_pt_jesTotalup}, {FatJet_mass_jesTotaldown, FatJet_mass_jesTotalup}, {PuppiMET_T1_pt_jesTotaldown_vec, PuppiMET_T1_pt_jesTotalup_vec}, {PuppiMET_T1_phi_jesTotaldown_vec, PuppiMET_T1_phi_jesTotalup_vec}, {TopMixed_pt_jesTotaldown, TopMixed_pt_jesTotalup}, {TopResolved_pt_jesTotaldown, TopResolved_pt_jesTotalup}, {TopMixed_mass_jesTotaldown, TopMixed_mass_jesTotalup}, {TopResolved_mass_jesTotaldown, TopResolved_mass_jesTotalup}, {TopMixed_TopScore_jesTotaldown, TopMixed_TopScore_jesTotalup}, {TopResolved_TopScore_jesTotaldown, TopResolved_TopScore_jesTotalup}}\", variationTags=[\"down\", \"up\"], variationName=\"jesTotal\")\n",
    "    return df_sys\n",
    "def SF_variations(df):\n",
    "    df_sys = df.Vary(\"puWeight\", \"RVec<float>{puWeightDown, puWeightUp}\", variationTags=[\"down\", \"up\"], variationName=\"pu\")\n",
    "    return df_sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69f0bf61-b2ab-422e-8baf-9abba2b984cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookhisto(df, regions_def, var, s_cut):\n",
    "    h_ = {}\n",
    "    for reg in regions_def.keys():\n",
    "        h_[reg] = {}\n",
    "        for v in var:\n",
    "            if v._MConly and not sampleflag: \n",
    "                continue\n",
    "            else:\n",
    "                # print(v._name+\"_\"+reg+\"_\"+s_cut)\n",
    "                if regions_def[reg] == \"\":\n",
    "                    if \"NoPu\" in reg: \n",
    "                        h_[reg][v._name]= df.Histo1D((v._name+\"_\"+reg,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name)\n",
    "                    else: \n",
    "                        h_[reg][v._name]= df.Histo1D((v._name+\"_\"+reg,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name, \"w_nominal\")\n",
    "                else:\n",
    "                    if \"NoPu\" in reg: \n",
    "                        h_[reg][v._name]= df.Filter(regions_def[reg]).Histo1D((v._name+\"_\"+reg,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name)\n",
    "                    else: h_[reg][v._name]= df.Filter(regions_def[reg]).Histo1D((v._name+\"_\"+reg,\" ;\"+v._title, v._nbins, v._xmin, v._xmax), v._name, \"w_nominal\")\n",
    "    return h_\n",
    "\n",
    "def bookhisto2D(df, regions_def, var2d, s_cut):\n",
    "    h_ = {}\n",
    "    for reg in regions_def.keys():\n",
    "        h_[reg] = {}\n",
    "        for v in var2d:\n",
    "            if regions_def[reg]==\"\":\n",
    "                h_[reg][v._name] = df.Redefine(v._xname, \"UnOvBin(\"+v._xname+\",\"+str(v._nxbins)+\",\"+str(v._xmin)+\",\"+str(v._xmax)+\")\")\\\n",
    "                                     .Redefine(v._yname, \"UnOvBin(\"+v._yname+\",\"+str(v._nybins)+\",\"+str(v._ymin)+\",\"+str(v._ymax)+\")\")\\\n",
    "                                     .Histo2D((v._xname+\"Vs\"+v._yname+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._xtitle+\";\"+v._ytitle, v._nxbins, v._xmin, v._xmax, v._nybins, v._ymin, v._ymax), v._xname, v._yname)\n",
    "            else:\n",
    "                h_[reg][v._name] = df.Filter(regions_def[reg])\\\n",
    "                                     .Redefine(v._xname, \"UnOvBin(\"+v._xname+\",\"+str(v._nxbins)+\",\"+str(v._xmin)+\",\"+str(v._xmax)+\")\")\\\n",
    "                                     .Redefine(v._yname, \"UnOvBin(\"+v._yname+\",\"+str(v._nybins)+\",\"+str(v._ymin)+\",\"+str(v._ymax)+\")\")\\\n",
    "                                     .Histo2D((v._xname+\"Vs\"+v._yname+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._xtitle+\";\"+v._ytitle, v._nxbins, v._xmin, v._xmax, v._nybins, v._ymin, v._ymax), v._xname, v._yname)\n",
    "    return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37967949-f502-4c77-9ceb-dd04f8062cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def savehisto(d, dict_h, regions_def, var, s_cut):\n",
    "    histo = {reg: {v._name: ROOT.TH1D(v._name+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax) for v in var} for reg in regions_def.keys()}\n",
    "    isMC=True\n",
    "    if \"Data\" in d.label: isMC = False\n",
    "    if hasattr(d, \"components\"):\n",
    "        s_list = d.components\n",
    "    else:\n",
    "        s_list = [d]\n",
    "    \n",
    "    for s in s_list:\n",
    "        outfile = ROOT.TFile.Open(repohisto+s.label+'.root', \"RECREATE\")\n",
    "\n",
    "        for n, vari in enumerate(variations):\n",
    "            for reg in regions_def.keys():\n",
    "                for v in var:\n",
    "                    if \"SFbtag\" in v._name: continue\n",
    "                    if v._MConly and not isMC:\n",
    "                        continue\n",
    "                    else:\n",
    "                        # da capire come fare il getvalue e dividere le variazioni\n",
    "                        if isMC:\n",
    "                            if do_variations:\n",
    "                                if vari=='nominal':\n",
    "                                    h1 = dict_h[d.label][s.label][reg][v._name][\"nominal\"]\n",
    "                                    h1.SetName(h1.GetName()+\"_nominal\")\n",
    "                                    nbins = h1.GetNbinsX()\n",
    "                                    if not v._noUnOvFlowbin:\n",
    "                                        h1.SetBinContent(1, h1.GetBinContent(0) + h1.GetBinContent(1))\n",
    "                                        h1.SetBinError(1, math.sqrt(pow(h1.GetBinError(0),2) + pow(h1.GetBinError(1),2)))\n",
    "                                        h1.SetBinContent(nbins, h1.GetBinContent(nbins) + h1.GetBinContent(nbins+1))\n",
    "                                        h1.SetBinError(nbins, math.sqrt(pow(h1.GetBinError(nbins),2) + pow(h1.GetBinError(nbins+1),2)))\n",
    "                                    if isMC:\n",
    "                                        h1.Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                    histo_name = h1.GetName()\n",
    "                                    if \"nominal\" not in histo_name : h1.SetName(histo_name+\"_nominal\")\n",
    "                                    outfile.cd()\n",
    "                                    h1.Write()\n",
    "                                else:\n",
    "                                    for var_type in ['up', 'down']:\n",
    "                                        h1 = dict_h[d.label][s.label][reg][v._name][vari+\":\"+var_type]\n",
    "                                        # h1.SetName(h1.GetName()+\"_\"+vari+var_type.capitalize())\n",
    "                                        histo_name = h1.GetName()\n",
    "                                        if vari+\"_\"+var_type not in histo_name:\n",
    "                                            h1.SetName(h1.GetName()+\"_\"+vari+\"_\"+var_type)\n",
    "                                        if not v._noUnOvFlowbin:\n",
    "                                            nbins = h1.GetNbinsX()\n",
    "                                            h1.SetBinContent(1, h1.GetBinContent(0) + h1.GetBinContent(1))\n",
    "                                            h1.SetBinError(1, math.sqrt(pow(h1.GetBinError(0),2) + pow(h1.GetBinError(1),2)))\n",
    "                                            h1.SetBinContent(nbins, h1.GetBinContent(nbins) + h1.GetBinContent(nbins+1))\n",
    "                                            h1.SetBinError(nbins, math.sqrt(pow(h1.GetBinError(nbins),2) + pow(h1.GetBinError(nbins+1),2)))\n",
    "                                            \n",
    "                                            # Tommaso aggiunge anche questo loop, ma non so bene a cosa serve\n",
    "                                            # for i in range(0, nbins + 1):          \n",
    "                                            #     if h1.GetBinContent(i) < 0:\n",
    "                                            #         h1.SetBinContent(i, 0.)\n",
    "                                        \n",
    "                                        if isMC:\n",
    "                                            h1.Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                        outfile.cd()\n",
    "                                        h1.Write()\n",
    "                            else:\n",
    "                                histo[reg][v._name] = dict_h[d.label][s.label][reg][v._name].GetValue()      \n",
    "                                if not v._noUnOvFlowbin:\n",
    "                                    nbins = histo[reg][v._name].GetNbinsX()\n",
    "                                    histo[reg][v._name].SetBinContent(1, histo[reg][v._name].GetBinContent(0) + histo[reg][v._name].GetBinContent(1))\n",
    "                                    histo[reg][v._name].SetBinError(1, math.sqrt(pow(histo[reg][v._name].GetBinError(0),2) + pow(histo[reg][v._name].GetBinError(1),2)))\n",
    "                                    histo[reg][v._name].SetBinContent(nbins, histo[reg][v._name].GetBinContent(nbins) + histo[reg][v._name].GetBinContent(nbins+1))\n",
    "                                    histo[reg][v._name].SetBinError(nbins, math.sqrt(pow(histo[reg][v._name].GetBinError(nbins),2) + pow(histo[reg][v._name].GetBinError(nbins+1),2)))\n",
    "                                if isMC:\n",
    "                                    histo[reg][v._name].Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                                outfile.cd()\n",
    "                                histo[reg][v._name].Write()\n",
    "                        else:\n",
    "                            histo[reg][v._name] = dict_h[d.label][s.label][reg][v._name].GetValue()\n",
    "                            if not v._noUnOvFlowbin:\n",
    "                                nbins = histo[reg][v._name].GetNbinsX()\n",
    "                                histo[reg][v._name].SetBinContent(1, histo[reg][v._name].GetBinContent(0) + histo[reg][v._name].GetBinContent(1))\n",
    "                                histo[reg][v._name].SetBinError(1, math.sqrt(pow(histo[reg][v._name].GetBinError(0),2) + pow(histo[reg][v._name].GetBinError(1),2)))\n",
    "                                histo[reg][v._name].SetBinContent(nbins, histo[reg][v._name].GetBinContent(nbins) + histo[reg][v._name].GetBinContent(nbins+1))\n",
    "                                histo[reg][v._name].SetBinError(nbins, math.sqrt(pow(histo[reg][v._name].GetBinError(nbins),2) + pow(histo[reg][v._name].GetBinError(nbins+1),2)))\n",
    "                            if isMC:\n",
    "                                histo[reg][v._name].Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                            outfile.cd()\n",
    "                            histo[reg][v._name].Write()\n",
    "        outfile.Close()\n",
    "\n",
    "# i plot2d per il momento non ci servono, si deve trovare un modo più intelligente di farli\n",
    "def savehisto2d(d, h, regions_def, var2d, s_cut):\n",
    "    histo = {reg: {v._name: ROOT.TH2D(v._name+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._xtitle+\";\"+v._ytitle, v._nxbins, v._xmin, v._xmax, v._nybins, v._ymin, v._ymax,) for v in var2d} for reg in regions_def.keys()}\n",
    "        \n",
    "    if hasattr(d, \"components\"):\n",
    "        s_list = d.components\n",
    "    else:\n",
    "        s_list = [d]\n",
    "    \n",
    "    for s in s_list:\n",
    "        outfile = ROOT.TFile.Open(repohisto+s.label+'_2D.root', \"RECREATE\")\n",
    "        for reg in regions_def.keys():\n",
    "            for v in histo[reg].keys():\n",
    "                histo[reg][v] = h[d.label][s.label][reg][v].GetValue()\n",
    "                if isMC:\n",
    "                    histo[reg][v._name].Scale(s.sigma*10**3/ntot_events[d.label][s.label])\n",
    "                outfile.cd()\n",
    "                histo[reg][v].Write()\n",
    "        outfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c96d28-45f4-4877-8d00-680e095a3016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#samples['DataHTF_2022']['DataHTF_2022']['strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab036200-65f9-44a0-abbb-8a04003fc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples[d.label][d.components[0]]['strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b72ddfd-d641-437d-a78c-8568a0a17a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop on datasets:  ['TprimeToTZ_1700_2022']\n",
      "Local time : 2025-01-08 17:59:47.800271\n",
      "Initializing DataFrame for TprimeToTZ_1700_2022 chain len =  1\n",
      "['root://stormgf2.pi.infn.it//store/user/acagnott/Run3Analysis_Tprime/TprimeToTZ_1700_2022/20241026_174706/tree_hadd_0.root']\n",
      "applying vary\n",
      "All histos booked !\n",
      "dict_keys(['TprimeToTZ_1700_2022'])\n",
      "TprimeToTZ_1700_2022 histos saved\n",
      "Job finished in:  0:00:56.290475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TClass::Init>: no dictionary for class edm::Hash<1> is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::ProcessHistory is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::ProcessConfiguration is available\n",
      "Warning in <TClass::Init>: no dictionary for class edm::ParameterSetBlob is available\n",
      "Warning in <TClass::Init>: no dictionary for class pair<edm::Hash<1>,edm::ParameterSetBlob> is available\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"starting loop on datasets: \",[d.label for d in datasets])\n",
    "print(\"Local time :\", t0)\n",
    "# print(\"requirements: \"+cut)\n",
    "\n",
    "h = {}\n",
    "h_2D = {}\n",
    "if do_variations:\n",
    "    h_varied = {}\n",
    "\n",
    "for d in datasets:\n",
    "    s_list = []\n",
    "    if hasattr(d, \"components\"):\n",
    "        s_list = d.components\n",
    "    else:\n",
    "        s_list = [d]\n",
    "    if 'Data' in d.label : sampleflag = 0\n",
    "    else: sampleflag = 1\n",
    "    c_ = cut\n",
    "    h[d.label] = {}\n",
    "    h_2D[d.label] = {}\n",
    "    if do_variations:\n",
    "        h_varied[d.label]={}\n",
    "    for s in s_list:\n",
    "        #-------------------------------------------------------------------------\n",
    "        ############# Fixing variables for 2018-2022 #############################\n",
    "        #-------------------------------------------------------------------------\n",
    "        if s.year == 2018:\n",
    "            bTagAlg = \"Jet_btagDeepB\"\n",
    "        elif s.year == 2022:\n",
    "            bTagAlg = \"Jet_btagPNetB\"\n",
    "        if hasattr(s,\"EE\"):\n",
    "            EE = s.EE\n",
    "        else:\n",
    "            EE = 0\n",
    "        #-------------------------------------------------------------------------\n",
    "        #########################  DF initialization #############################\n",
    "        #-------------------------------------------------------------------------\n",
    "        \n",
    "        print(\"Initializing DataFrame for \"+ s.label +\" chain len = \", len(chain[d.label][s.label]))\n",
    "        if len(chain[d.label][s.label])==1: print(chain[d.label][s.label])\n",
    "        if distributed ==True:\n",
    "            df = RDataFrame(\"Events\", chain[d.label][s.label], npartitions=nmaxpartition, \n",
    "                            daskclient=client, monitor_label = \"main\" )\n",
    "        else:\n",
    "            df = RDataFrame(\"Events\", chain[d.label][s.label])\n",
    "        df = df.Define(\"PuppiMET_T1_pt_nominal_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_nominal}\").Define(\"PuppiMET_T1_phi_nominal_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_nominal}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jerdown_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jerdown}\").Define(\"PuppiMET_T1_phi_jerdown_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jerdown}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jerup_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jerup}\").Define(\"PuppiMET_T1_phi_jerup_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jerup}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jesTotaldown_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jesTotaldown}\").Define(\"PuppiMET_T1_phi_jesTotaldown_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jesTotaldown}\")\\\n",
    "               .Define(\"PuppiMET_T1_pt_jesTotalup_vec\", \"RVec<float>{ (float) PuppiMET_T1_pt_jesTotalup}\").Define(\"PuppiMET_T1_phi_jesTotalup_vec\", \"RVec<float>{ (float) PuppiMET_T1_phi_jesTotalup}\")\n",
    "        if do_variations:\n",
    "            df              = SF_variations(df)\n",
    "            df              = energetic_variations(df)\n",
    "        else:\n",
    "            df              = df\n",
    "        df_ismc         = df.Define(\"isMC\", \"isMC(\"+str(sampleflag)+\")\")\n",
    "        df_year         = df_ismc.Define(\"year\", str(s.year))\n",
    "        df_hemveto      = df_year.Define(\"HEMVeto\", \"hemveto(Jet_eta, Jet_phi, Electron_eta, Electron_phi)\")\n",
    "        df_hemveto      = df_hemveto.Filter(\"(isMC || (year != 2018) || (HEMVeto || run<319077.))\")\n",
    "        df_hlt          = trigger_filter(df_hemveto, s.label, sampleflag)\n",
    "        \n",
    "        if \"ZJets\" in s.label: \n",
    "            df_hlt = df_hlt.Define(\"w_nominal\", \"nloewcorrectionZ(1., GenPart_pdgId, GenPart_pt, GenPart_statusFlags)\")\n",
    "        elif \"WJets\" in s.label:\n",
    "            df_hlt = df_hlt.Define(\"w_nominal\", \"nloewcorrectionW(1., GenPart_pdgId, GenPart_pt, GenPart_statusFlags)\")\n",
    "        else:\n",
    "            df_hlt = df_hlt.Define(\"w_nominal\", \"1\")\n",
    "            \n",
    "        if sampleflag: df_wnom = df_hlt.Redefine('w_nominal', 'w_nominal*puWeight*SFbtag_nominal*(LHEWeight_originalXWGTUP/abs(LHEWeight_originalXWGTUP))')  \n",
    "        else: df_wnom           = df_hlt.Redefine('w_nominal', '1')\n",
    "\n",
    "            \n",
    "        # df_wnom           = df_hlt.Define('w_nominal', '1')\n",
    "        df_presel       = preselection(df_wnom, bTagAlg, s.year, EE)\n",
    "        df_topsel       = select_top(df_presel, sampleflag)\n",
    "        df_topsel       = df_topsel.Define(\"MT_T\", \"sqrt(2 * Top_pt * PuppiMET_T1_pt_nominal * (1 - cos(Top_phi - PuppiMET_T1_phi_nominal)))\")\n",
    "        \n",
    "        if do_snapshot:\n",
    "            opts = ROOT.RDF.RSnapshotOptions()\n",
    "            opts.fLazy = True\n",
    "            if distributed: fold = \"./\"\n",
    "            else: fold = folder\n",
    "            snapshot_df = df_topsel.Snapshot(\"events_nominal\", fold+\"snap_\"+s.label+\".root\", branches, opts)\n",
    "            # print(\"./\"+s.label+\".root\")\n",
    "        if do_histos:\n",
    "            s_cut = cut_string(cut)\n",
    "            if len(var) != 0 :\n",
    "                h[d.label][s.label] = bookhisto(df_topsel, regions_def, var, s_cut)\n",
    "            if len(var2d) != 0 :\n",
    "                h_2D[d.label][s.label] = bookhisto2D(df_topsel, regions_def, var2d, s_cut)\n",
    "\n",
    "        \n",
    "        if do_variations:\n",
    "            # h [dataset][label][region][variable]\n",
    "            print(\"applying vary\")\n",
    "            h_varied[d.label][s.label]={}\n",
    "            for reg in regions_def.keys():\n",
    "                h_varied[d.label][s.label][reg] = {}\n",
    "                for v in var:\n",
    "                    if \"SFbtag\" in v._name: continue\n",
    "                    if distributed == True:\n",
    "                        h_varied[d.label][s.label][reg][v._name] = ROOT.RDF.Experimental.Distributed.VariationsFor(h[d.label][s.label][reg][v._name])\n",
    "                    else:\n",
    "                        h_varied[d.label][s.label][reg][v._name] = ROOT.RDF.Experimental.VariationsFor(h[d.label][s.label][reg][v._name])\n",
    "\n",
    "if do_histos:\n",
    "    print(\"All histos booked !\")\n",
    "    for d in datasets:\n",
    "        if len(var):\n",
    "            if do_variations:\n",
    "                print(h_varied.keys())\n",
    "                # print(h_varied[d.label].keys())\n",
    "                savehisto(d, h_varied, regions_def, var, s_cut)\n",
    "            else:\n",
    "                savehisto(d, h, regions_def, var, s_cut)\n",
    "        if len(var2d) != 0 :\n",
    "            savehisto2d(d, h_2D, regions_def, var2d, s_cut)\n",
    "        print(d.label + \" histos saved\")\n",
    "if do_snapshot:\n",
    "    snapshot_df.GetValue()\n",
    "    if distributed: \n",
    "        client.run(transfer_to_tier)\n",
    "        print(\"Snapshots saved and trasfered to tier\")\n",
    "    print(\"Sanpshot done!\")\n",
    "t1 = datetime.now()\n",
    "print(\"Job finished in: \", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16fe229-69f3-4a0e-ae7c-c754c3fcda20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results/test/plots/TprimeToTZ_1700_2022'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repohisto+s.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9573b747-9a5a-4501-b084-481b10d418ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: ./results/test/plots/TprimeToTZ_1700_2022.root Title: \n",
      "SR 0.006123737622767685\n",
      "SR0fjets 0.0010713584188361059\n",
      "SRatleast1fjets 0.005052379203931579\n",
      "ResSR 0.0\n",
      "ResSR0fjets 0.0\n",
      "ResSRatleast1fjets 0.0\n",
      "MixSR 0.00010090720522214065\n",
      "MixSR0fjets 2.0954844961924986e-05\n",
      "MixSRatleast1fjets 7.995236026021567e-05\n",
      "MerSR 0.003136425704479826\n",
      "MerSR0fjets 0.0005432318498815326\n",
      "MerSRatleast1fjets 0.0025931938545982946\n",
      "SRTop 0.0032373329097019673\n",
      "SRTop0fjets 0.0005641866948434576\n",
      "SRTopatleast1fjets 0.0026731462148585103\n",
      "AH 0.10695399614018401\n",
      "SL 0.07401430437261221\n",
      "AH1lWR 0.004805709714707598\n",
      "AH0lZR 0.0007868726484951307\n"
     ]
    }
   ],
   "source": [
    "file = ROOT.TFile.Open(repohisto+s.label+\".root\")\n",
    "print(file)\n",
    "# for a in file.GetListOfKeys(): print(a)\n",
    "for reg in regions_def.keys():\n",
    "    # for v in var:\n",
    "    hist = file.Get(var[22]._name+\"_\"+reg+\"_nominal\")\n",
    "    print(reg, hist.Integral())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3606a5b-e3ce-491d-a86a-6c02431ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syst = \"jer\"\n",
    "\n",
    "# h = file.Get(\"PuppiMET_T1_pt_SR__nominal\")\n",
    "# h.SetLineColor(ROOT.kBlue)\n",
    "# h1 = file.Get(\"PuppiMET_T1_pt_SR__\"+syst+\"Down\")\n",
    "# h1.SetLineColor(ROOT.kRed)\n",
    "# h2 = file.Get(\"PuppiMET_T1_pt_SR__\"+syst+\"Up\")\n",
    "# h2.SetLineColor(ROOT.kGreen)\n",
    "# c = ROOT.TCanvas()\n",
    "# c.Draw()\n",
    "# h.Draw(\"HIST\")\n",
    "# h1.Draw(\"HIST same\")\n",
    "# h2.Draw(\"HIST same\")\n",
    "# c.SetLogy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "269963fc-638b-4a19-8c8d-af26bad6e37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cppyy.gbl.ROOT.RDF.Experimental.RResultMap<TH1D> object at 0x55f4787813d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_varied[d.label][s.label][\"SR\"][\"PuppiMET_pt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8daa57df-4a5e-46d7-b758-84edcebca76a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if do_snapshot and distributed:\n",
    "    print(os.popen(\"davix-ls davs://stwebdav.pi.infn.it:8443/cms/store/user/acagnott/{}/{}/ -E /tmp/x509up_u0 --capath /cvmfs/cms.cern.ch/grid/etc/grid-security/certificates/\".format(remote_folder_name, remote_subfolder_name)).read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890dba80-c7ab-4901-8df6-401b227b9b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ba5c96-ad75-4d34-a8b9-b5e06746282a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05068ab-ea06-42da-a3ee-32893dbd6fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4ed52-c2be-454a-9867-a3a616bbcc96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56665013-ff33-46db-90e1-d479c5088f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Singularity kernel - Base ROOT 6.32.02 + CMSJMECalculator 0.2.0 + Correctionlib 2.6.1",
   "language": "python",
   "name": "singularity-kernel-root"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
