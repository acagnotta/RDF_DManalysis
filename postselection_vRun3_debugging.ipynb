{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd081e3",
   "metadata": {},
   "source": [
    "New Version for RUN 3 DATA/MC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e16aaf3-78d5-4a3c-851c-21f771dcf586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.27/01\n",
      "/tmp/x509up_u0 /cvmfs/grid.cern.ch/etc/grid-security/certificates/\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import os\n",
    "from utils.samples import *\n",
    "from utils.variables import *\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from dask.distributed import Client\n",
    "from datetime import datetime\n",
    "ROOT.RDF.Experimental.Distributed.open_files_locally = False\n",
    "\n",
    "os.environ['X509_CERT_DIR'] = \"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "os.environ['X509_USER_PROXY'] = \"/tmp/x509up_u0\"\n",
    "print(os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3271c9-56c5-4ee1-a501-f85177699ab8",
   "metadata": {},
   "source": [
    "Fixed parameters definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00f446ef-90d9-46e8-ad16-8ded4fa2fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = requirements # ---> vedi variables.py\n",
    "in_dataset = [\n",
    "    \"DataHTA_2018\", \n",
    "    # \"DataHTB_2018\", \n",
    "    # \"DataHTC_2018\",\n",
    "    # \"DataHTD_2018\",\n",
    "    # \"TprimeToTZ_700_2018\", \n",
    "    # \"TprimeToTZ_1000_2018\", \n",
    "    # \"TprimeToTZ_1800_2018\",\n",
    "    # \"QCDHT_100to200_2018\", \n",
    "    # \"QCDHT_200to300_2018\",\n",
    "    # \"QCDHT_300to500_2018\", \n",
    "    # \"QCDHT_500to700_2018\", \n",
    "    # \"QCDHT_700to1000_2018\",\n",
    "    # \"QCDHT_1000to1500_2018\", \n",
    "    # \"QCDHT_1500to2000_2018\",\n",
    "    # \"QCDHT_2000toInf_2018\",\n",
    "    # \"TT_hadr_2018\", \n",
    "    # \"TT_semilep_2018\", \n",
    "    # \"TT_Mtt700to1000_2018\", \n",
    "    # \"TT_Mtt1000toInf_2018\",\n",
    "    # \"ZJetsToNuNu_HT100to200_2018\", \n",
    "    # \"ZJetsToNuNu_HT200to400_2018\", \n",
    "    # \"ZJetsToNuNu_HT400to600_2018\", \n",
    "    # \"ZJetsToNuNu_HT600to800_2018\", \n",
    "    # \"ZJetsToNuNu_HT800to1200_2018\", \n",
    "    # \"ZJetsToNuNu_HT1200to2500_2018\", \n",
    "    # \"ZJetsToNuNu_HT2500toInf_2018\"\n",
    "    # \"WJetsHT100to200_2018\", \n",
    "    # \"WJetsHT200to400_2018\", \n",
    "    # \"WJetsHT400to600_2018\", \n",
    "    # \"WJetsHT600to800_2018\", \n",
    "    # \"WJetsHT800to1200_2018\", \n",
    "    # \"WJetsHT1200to2500_2018\", \n",
    "    # \"WJetsHT2500toInf_2018\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54586805-5e2c-4b36-a13b-11497d5f2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invLepveto = \"\"#\"!\" # per non invertirlo basta passare stinga vuota\n",
    "# met_cut = 250\n",
    "# mdphi_cut = 0\n",
    "# HLT_filter = \"HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29461d93-e531-41df-a8c3-1fd0298ef13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## params cluster\n",
    "\n",
    "sched_port = 24745 #Dask port\n",
    "nmaxpartition = 20 # to set at lower value\n",
    "distributed = True#False#\n",
    "if distributed:\n",
    "    nfiles_max = 999\n",
    "else:\n",
    "    nfiles_max = 1  #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63e6103-21cf-4437-9d7b-2562eeb75059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output folder ---> waiting to implement davix lib\n",
    "folder = \"./results/run2018_EXO22014_presel/\"# \"./results/run2018_benchmark_deb/\" #\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "repohisto = folder+\"plots/\"\n",
    "if not os.path.exists(repohisto):\n",
    "    os.mkdir(repohisto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31a9be5b-2e52-431b-9709-ee1c3e639b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/distributed/client.py:1128: VersionMismatchWarning: Mismatched versions found\n",
      "\n",
      "+---------+--------+-----------+---------+\n",
      "| Package | client | scheduler | workers |\n",
      "+---------+--------+-----------+---------+\n",
      "| msgpack | 1.0.3  | 1.0.2     | 1.0.3   |\n",
      "| toolz   | 0.11.2 | 0.11.1    | 0.11.2  |\n",
      "+---------+--------+-----------+---------+\n",
      "Notes: \n",
      "-  msgpack: Variation is ok, as long as everything is above 0.6\n",
      "  warnings.warn(version_module.VersionMismatchWarning(msg[0][\"warning\"]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "end of initialization\n"
     ]
    }
   ],
   "source": [
    "# initialization of clusters\n",
    "\n",
    "# upload the proxyfile to the Dask workers to make them able to access data on the grid \n",
    "\n",
    "from distributed.diagnostics.plugin import UploadFile\n",
    "def set_proxy(dask_worker):\n",
    "    import os\n",
    "    import shutil\n",
    "    working_dir = dask_worker.local_directory\n",
    "    proxy_name = 'x509up_u0'\n",
    "    os.environ['X509_USER_PROXY'] = working_dir + '/' + proxy_name\n",
    "    os.environ['X509_CERT_DIR']=\"/cvmfs/grid.cern.ch/etc/grid-security/certificates/\"\n",
    "    shutil.copyfile(working_dir + '/x509up_u0', working_dir + '/../../../x509up_u0')    \n",
    "    os.environ['EXTRA_CLING_ARGS'] = \"-O2\"\n",
    "    return os.environ.get(\"X509_USER_PROXY\"), os.environ.get(\"X509_CERT_DIR\")\n",
    "\n",
    "text_file = open(\"utils/postselection.h\", \"r\")\n",
    "data = text_file.read()\n",
    "def my_initialization_function():\n",
    "    print(ROOT.gInterpreter.ProcessLine(\".O\"))\n",
    "    ROOT.gInterpreter.Declare('{}'.format(data))\n",
    "    print(\"end of initialization\")\n",
    "\n",
    "# set up everything properly\n",
    "if distributed == True:\n",
    "    RDataFrame = ROOT.RDF.Experimental.Distributed.Dask.RDataFrame\n",
    "    client = Client(address=\"tcp://127.0.0.1:\"+str(sched_port))\n",
    "    client.restart()\n",
    "    client.register_worker_plugin(UploadFile(\"/tmp/x509up_u0\"))\n",
    "    client.run(set_proxy)\n",
    "    ROOT.RDF.Experimental.Distributed.initialize(my_initialization_function)\n",
    "else:\n",
    "    RDataFrame = ROOT.RDataFrame\n",
    "    my_initialization_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e40aec",
   "metadata": {},
   "source": [
    "Regions definitions for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c3b1a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NoCut': '', 'HEMVeto': '((!isMC && year == 2018) && (HEMVeto || run<319077.))', 'HEMVeto_HLT_MET_filters': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter)) ', 'HEMVeto_HLT_MET_filters_METcut': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250)', 'AH': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250) && (nVetoMuon+nVetoElectron) == 0 && nJetBtag > 0 && nGoodJet>3', 'SL': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250) && ((nTightElectron == 1 && nVetoElectron == 1 && nTightMuon == 0 && nVetoMuon == 0)||(nTightElectron == 0 && nVetoElectron == 0 && nTightMuon == 1 && nVetoMuon == 1)) && nJetBtag > 0', 'SMu': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250) && (nTightElectron == 0 && nVetoElectron == 0 && nTightMuon == 1 && nVetoMuon == 1) && nJetBtag > 0', 'SEl': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250) && (nTightElectron == 1 && nVetoElectron == 1 && nTightMuon == 0 && nVetoMuon == 0) && nJetBtag > 0', 'AH1lWR': '((!isMC && year == 2018) && (HEMVeto || run<319077.)) && ((HLT_PFMETNoMu120_PFMHTNoMu120_IDTight_PFHT60 || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight || HLT_Ele32_WPTight_Gsf || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_IsoMu24) && MET_filter(Flag_goodVertices, Flag_globalSuperTightHalo2016Filter, Flag_HBHENoiseFilter, Flag_HBHENoiseIsoFilter, Flag_EcalDeadCellTriggerPrimitiveFilter, Flag_BadPFMuonFilter, Flag_ecalBadCalibFilter, Flag_eeBadScFilter))  && (MET_pt>250) && ((nTightElectron == 1 && nVetoElectron == 1 && nTightMuon == 0 && nVetoMuon == 0)||(nTightElectron == 0 && nVetoElectron == 0 && nTightMuon == 1 && nVetoMuon == 1)) && nGoodJet>=3 && MT<=140 && nJetBtag == 0'}\n"
     ]
    }
   ],
   "source": [
    "regions_def = regions # ---> vedi variables.py\n",
    "# {\n",
    "#     \"all_regions\" : \"\"\n",
    "#     # \"resolved_1fwjet\": \"EventTopCategory==3 && nForwardJet>0\", \n",
    "#     # \"mixed_1fwjet\": \"EventTopCategory==2 && nForwardJet>0\", \n",
    "#     # \"merged_1fwjet\": \"EventTopCategory==1 && nForwardJet>0\",\n",
    "#     # \"resolved_0fwjet\": \"EventTopCategory==3 && nForwardJet==0\", \n",
    "#     # \"mixed_0fwjet\": \"EventTopCategory==2 && nForwardJet==0\", \n",
    "#     # \"merged_0fwjet\" : \"EventTopCategory==1 && nForwardJet==0\",\n",
    "#     # \"noTopRegion\" : \"EventTopCategory==0\"\n",
    "# }\n",
    "print(regions_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e9de3f-0903-4934-9090-15e12c806b20",
   "metadata": {},
   "source": [
    "Importing dict samples with the info for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2fbdbd1-d1d8-4ddf-9d0d-10d6a7b7d631",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = open(\"utils/dict_samples.json\", \"rb\")\n",
    "samples = json.load(sample_file)\n",
    "sample_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29546c32",
   "metadata": {},
   "source": [
    "INPUT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06816863-d201-4852-b127-6bd885b566f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DataHTA_2018']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d23c148-5df3-45ff-ba4b-1ac967f420de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataHTA_2018\n"
     ]
    }
   ],
   "source": [
    "if not in_dataset[0] in sample_dict.keys():\n",
    "    datasets = []\n",
    "    print(\"Check the in_dataset string... \", sample_dict.keys())\n",
    "else : \n",
    "    datasets= []\n",
    "    for d in in_dataset:\n",
    "        datasets.append(sample_dict[d])\n",
    "        print(datasets[-1].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "682c7555-c07d-4899-b7d1-12cef3783084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['QCD_2018', 'QCDHT_100to200_2018', 'QCDHT_200to300_2018', 'QCDHT_300to500_2018', 'QCDHT_500to700_2018', 'QCDHT_700to1000_2018', 'QCDHT_1000to1500_2018', 'QCDHT_1500to2000_2018', 'QCDHT_2000toInf_2018', 'ZJetsToNuNu_2018', 'ZJetsToNuNu_HT100to200_2018', 'ZJetsToNuNu_HT200to400_2018', 'ZJetsToNuNu_HT400to600_2018', 'ZJetsToNuNu_HT600to800_2018', 'ZJetsToNuNu_HT800to1200_2018', 'ZJetsToNuNu_HT1200to2500_2018', 'ZJetsToNuNu_HT2500toInf_2018', 'TT_2018', 'TT_hadr_2018', 'TT_semilep_2018', 'TT_Mtt1000toInf_2018', 'TT_Mtt700to1000_2018', 'WJets_2018', 'WJetsHT100to200_2018', 'WJetsHT200to400_2018', 'WJetsHT400to600_2018', 'WJetsHT600to800_2018', 'WJetsHT800to1200_2018', 'WJetsHT1200to2500_2018', 'WJetsHT2500toInf_2018', 'TprimeToTZ_700_2018', 'TprimeToTZ_1000_2018', 'TprimeToTZ_1800_2018', 'DataHT_2018', 'DataHTA_2018', 'DataHTB_2018', 'DataHTC_2018', 'DataHT_2022', 'DataHTC_2022', 'DataHTD_2022', 'DataHTE_2022', 'DataHTF_2022', 'DataHTG_2022', 'DataHTD_2018', 'DataHTH_2016', 'DataMETA_2018'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647f503d",
   "metadata": {},
   "source": [
    "Variables to plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "616688c8-eb99-452d-b66c-cd938fcc2877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MET_pt', 'PuppiMET_pt', 'MET_phi', 'LeadingJetPt_pt', 'LeadingJetPt_eta', 'LeadingJetPt_phi', 'LeadingJetPt_mass', 'LeadingFatJetPt_pt', 'LeadingFatJetPt_eta', 'LeadingFatJetPt_phi', 'LeadingFatJetPt_mass', 'LeadingMuonPt_pt', 'LeadingMuonPt_eta', 'LeadingMuonPt_phi', 'LeadingElectronPt_pt', 'LeadingElectronPt_eta', 'LeadingElectronPt_phi', 'nTopHighPt', 'nTopLowPt', 'nJet', 'nJetBtag', 'nFatJet', 'MinDelta_phi', 'MaxEta_jet', 'HT_eventHT', 'run', 'PV_npvsGood']\n"
     ]
    }
   ],
   "source": [
    "#Defining variables to plot\n",
    "\n",
    "var = vars  # ---> vedi variables.py\n",
    "\n",
    "# var.append(variable(name = \"MET_pt\", title= \"MET p_{T} [GeV]\", taglio = cut, nbins = 20, xmin = 0, xmax=1000))\n",
    "# var.append(variable(name = \"MET_phi\", title= \"MET #phi\", taglio = cut, nbins = 6, xmin = -math.pi, xmax=math.pi))\n",
    "# var.append(variable(name = \"LeadingJet_pt\", title= \"Leading Jet p_{T} [GeV]\", taglio = cut, nbins = 30, xmin = 50, xmax=950))\n",
    "# var.append(variable(name = \"nTopHighPt\", title= \"# Top Candidate Mix\", taglio = cut, nbins = 80, xmin = -0.5, xmax=80.5))\n",
    "# var.append(variable(name = \"nTopLowPt\", title= \"# Top Candidate Resolved\", taglio = cut, nbins = 50, xmin = -0.5, xmax=50.5))\n",
    "# var.append(variable(name = \"nJet\", title= \"# Jet\", taglio = cut, nbins = 25, xmin = -0.5, xmax=25.5))\n",
    "# var.append(variable(name = \"nFatJet\", title= \"# FatJet\", taglio = cut, nbins = 25, xmin = -0.5, xmax=25.5))\n",
    "# var.append(variable(name = \"MinDelta_phi\", title= \"min #Delta #phi\", taglio = cut, nbins = 20, xmin = 0, xmax = 4))\n",
    "# var.append(variable(name = \"MaxEta_jet\", title= \"max #eta jet\", taglio = cut, nbins = 24, xmin = 0, xmax = 6))\n",
    "\n",
    "print([v._name for v in var])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "963af90a-de0c-44a7-9b64-3927c34eeffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### utils ###################\n",
    "def cut_string(cut):\n",
    "    return cut.replace(\" \", \"\").replace(\"&&\",\"_\").replace(\">\",\"_g_\").replace(\".\",\"_\").replace(\"==\",\"_e_\")\n",
    "\n",
    "################### preselection ###############\n",
    "def preselection(df):\n",
    "    df = df.Define(\"GoodJet_idx\", \"GetGoodJet(Jet_pt, Jet_eta, Jet_jetId)\")\n",
    "    df = df.Define(\"nGoodJet\", \"nGoodJet(GoodJet_idx)\")\n",
    "    \n",
    "    # if 'leptonveto' in cut:\n",
    "    #     df = df.Filter(invLepveto+\"LepVeto(Electron_pt, Electron_eta, Electron_cutBased, Muon_pt, Muon_eta, Muon_looseId )\", \"Lepton Veto\")\n",
    "    #     if \"&& leptonveto\" in cut:\n",
    "    #         c_ = cut.replace(\"&& leptonveto\",\"\")\n",
    "    #     elif \"leptonveto &&\" in cut:\n",
    "    #         c_ = cut.replace(\"leptonveto &&\",\"\")\n",
    "    #     elif \"leptonveto\" in cut:\n",
    "    #         c_ = cut.replace(\"leptonveto\",\"\")    \n",
    "    # else: \n",
    "    #     df = df\n",
    "    #     c_ = cut\n",
    "    df = df.Define(\"nTightElectron\", \"nTightElectron(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"TightElectron_idx\", \"TightElectron_idx(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"nVetoElectron\", \"nVetoElectron(Electron_pt, Electron_cutBased)\")\n",
    "    df = df.Define(\"nTightMuon\", \"nTightMuon(Muon_pt, Muon_eta, Muon_tightId)\")\n",
    "    df = df.Define(\"TightMuon_idx\", \"TightMuon_idx(Muon_pt, Muon_eta, Muon_tightId)\")\n",
    "    df = df.Define(\"nVetoMuon\", \"nVetoMuon(Muon_pt, Muon_eta, Muon_looseId)\")\n",
    "    df = df.Define(\"Lepton_flavour\", \"Lepton_flavour(nTightElectron, nTightMuon)\").Define(\"Lep_pt\", \"Lepton_var(Lepton_flavour, Electron_pt, TightElectron_idx, Muon_pt, TightMuon_idx)\").Define(\"Lep_phi\", \"Lepton_var(Lepton_flavour, Electron_phi, TightElectron_idx, Muon_phi, TightMuon_idx)\")\n",
    "    df = df.Define(\"MT\", \"sqrt(2 * Lep_pt * MET_pt * (1 - cos(Lep_phi - MET_phi)))\")\n",
    "    \n",
    "    # df = df.Filter(\"MET_pt>\"+ str(met_cut), \"MET_pt>\"+ str(met_cut))\n",
    "    # df = df.Filter(\"MinDelta_phi>\"+ str(mdphi_cut), \"MinDeltaPhi>\"+ str(mdphi_cut))\n",
    "    \n",
    "    # df = df.Filter(\"atLeast1jet_setparams(Jet_pt, Jet_eta, Jet_mass, Jet_jetId, 30, 4, 0, 1)\", \"At_least_1Ak4\")\n",
    "    # df = df.Filter(\"atLeast1fatjet_setparams(FatJet_pt, FatJet_msoftdrop, FatJet_eta, FatJet_jetId, 200, 6, 40, 1)\", \"at_least_1Ak8\")\n",
    "\n",
    "    df = df.Define(\"LeadingJetPt_idx\", \"GetLeadingPtJet(Jet_pt)\")\n",
    "    df = df.Define(\"LeadingJetPt_pt\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_pt)\")\n",
    "    df = df.Define(\"LeadingJetPt_eta\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_eta)\")\n",
    "    df = df.Define(\"LeadingJetPt_phi\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_phi)\")\n",
    "    df = df.Define(\"LeadingJetPt_mass\", \"GetLeadingJetVar(LeadingJetPt_idx, Jet_mass)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_idx\", \"GetLeadingPtJet(FatJet_pt)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_pt\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_pt)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_eta\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_eta)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_phi\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_phi)\")\n",
    "    df = df.Define(\"LeadingFatJetPt_mass\", \"GetLeadingJetVar(LeadingFatJetPt_idx, FatJet_mass)\")\n",
    "    df = df.Define(\"LeadingMuonPt_idx\", \"GetLeadingPtLep(Muon_pt, Muon_eta, Muon_looseId)\")\n",
    "    df = df.Define(\"LeadingMuonPt_pt\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_pt)\")\n",
    "    df = df.Define(\"LeadingMuonPt_eta\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_eta)\")\n",
    "    df = df.Define(\"LeadingMuonPt_phi\", \"GetLeadingJetVar(LeadingMuonPt_idx, Muon_phi)\")\n",
    "    df = df.Define(\"LeadingElectronPt_idx\", \"GetLeadingPtLep(Electron_pt, Electron_eta, Electron_cutBased)\")\n",
    "    df = df.Define(\"LeadingElectronPt_pt\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_pt)\")\n",
    "    df = df.Define(\"LeadingElectronPt_eta\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_eta)\")\n",
    "    df = df.Define(\"LeadingElectronPt_phi\", \"GetLeadingJetVar(LeadingElectronPt_idx, Electron_phi)\")\n",
    "    \n",
    "    df = df.Define(\"nForwardJet\", \"nForwardJet(GoodJet_idx, Jet_eta)\")\n",
    "    df = df.Define(\"nJetBtag\", \"njetbtag(GoodJet_idx, Jet_btagDeepFlavB)\")\n",
    "        \n",
    "    return df\n",
    "\n",
    "############### trigger selection #####################\n",
    "def trigger_filter(df):\n",
    "    #HLT_PFHT780 || HLT_PFHT890 || HLT_Mu50 || HLT_OldMu100 || HLT_TkMu100 || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_Ele35_WPTight_Gsf\n",
    "    #preso da MET_HLT_filter\n",
    "    #df_trig = df.Filter(\"HLT_PFHT780 || HLT_PFHT890 || HLT_Mu50 || HLT_OldMu100 || HLT_TkMu100 || HLT_Ele115_CaloIdVT_GsfTrkIdT || HLT_Photon200 || HLT_Ele35_WPTight_Gsf\")\n",
    "    df_trig = df.Filter(\" HLT_PFMET120_PFMHT120_IDTight || HLT_PFMETNoMu120_PFMHTNoMu120_IDTight\", \"trigger\")\n",
    "    # controllare la lista di trigger \n",
    "    return df_trig\n",
    "\n",
    "############### top selection ########################\n",
    "def select_top(df):\n",
    "    df_goodtopMer = df.Define(\"GoodTopMer_idx\", \"select_TopMer(FatJet_deepTag_TvsQCD, FatJet_pt, FatJet_eta, FatJet_phi)\")\n",
    "    # ritorna gli indici dei FatJet che superano la trs del Top Merged (no overlap)\n",
    "    df_goodtopMix = df_goodtopMer.Define(\"GoodTopMix_idx\", \"select_TopMix(TopHighPt_score2, TopHighPt_pt, TopHighPt_eta, TopHighPt_phi)\")\n",
    "    # ritorna gli indici dei FatJet che superano la trs del Top Merged (no overlap)\n",
    "    df_goodtopRes = df_goodtopMix.Define(\"GoodTopRes_idx\", \"select_TopRes(TopLowPt_scoreDNN, TopLowPt_pt, TopLowPt_eta, TopLowPt_phi)\")\n",
    "    # ritorna gli indici dei Fatche superano la trs del Top Merged (no overlap)\n",
    "    df_topcategory = df_goodtopRes.Define(\"EventTopCategory\", \"select_TopCategory(GoodTopMer_idx, GoodTopMix_idx, GoodTopRes_idx)\")\n",
    "    # return:  0- no top sel, 1- top merged, 2- top mix, 3- top resolved\n",
    "    df_topselected = df_topcategory.Define(\"Top_idx\",\n",
    "                                           \"select_bestTop(EventTopCategory, GoodTopMer_idx, GoodTopMix_idx, GoodTopRes_idx, FatJet_deepTag_TvsQCD, TopHighPt_score2, TopLowPt_scoreDNN)\")\n",
    "    # return best top idx wrt category --> the idx is referred to the list of candidates fixed by the EventTopCategory\n",
    "    df_topvariables = df_topselected.Define(\"Top_pt\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_pt, TopHighPt_pt, TopLowPt_pt)\")\\\n",
    "                        .Define(\"Top_eta\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_eta, TopHighPt_eta, TopLowPt_eta)\")\\\n",
    "                        .Define(\"Top_phi\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_phi, TopHighPt_phi, TopLowPt_phi)\")\\\n",
    "                        .Define(\"Top_mass\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_mass, TopHighPt_mass, TopLowPt_mass)\")\\\n",
    "                        .Define(\"Top_score\", \"select_TopVar(EventTopCategory, Top_idx, FatJet_deepTag_TvsQCD, TopHighPt_score2, TopLowPt_scoreDNN)\")\n",
    "\n",
    "    return df_topvariables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69f0bf61-b2ab-422e-8baf-9abba2b984cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookhisto(df, regions_def, var, s_cut):\n",
    "    h_ = {}\n",
    "    for reg in regions_def.keys():\n",
    "        h_[reg] = {}\n",
    "        for v in var:\n",
    "            if regions_def[reg] == \"\":\n",
    "                h_[reg][v._name]= df.Redefine(v._name, \"UnOvBin(\"+v._name+\",\"+str(v._nbins)+\",\"+str(v._xmin)+\",\"+str(v._xmax)+\")\").Histo1D((v._name+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name)\n",
    "            else:\n",
    "                h_[reg][v._name]= df.Filter(regions_def[reg]).Redefine(v._name, \"UnOvBin(\"+v._name+\",\"+str(v._nbins)+\",\"+str(v._xmin)+\",\"+str(v._xmax)+\")\").Histo1D((v._name+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax), v._name)\n",
    "    return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37967949-f502-4c77-9ceb-dd04f8062cd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def savehisto(d, h, regions_def, var, s_cut):\n",
    "    histo = {reg: {v._name: ROOT.TH1D(v._name+\"_\"+reg+\"_\"+s_cut,\" ;\"+v._title+\"\", v._nbins, v._xmin, v._xmax) for v in var} for reg in regions_def.keys()}\n",
    "    outfile = ROOT.TFile.Open(repohisto+d.label+'.root', \"RECREATE\")\n",
    "    s = [d]\n",
    "    for reg in regions_def.keys():\n",
    "        for v in var:\n",
    "            histo[reg][v._name] = h[reg][v._name].GetValue()      \n",
    "            outfile.cd()\n",
    "            histo[reg][v._name].Write()\n",
    "    outfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54c96d28-45f4-4877-8d00-680e095a3016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#samples['DataHTF_2022']['DataHTF_2022']['strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab036200-65f9-44a0-abbb-8a04003fc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#samples[d.label][d.components[0]]['strings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b72ddfd-d641-437d-a78c-8568a0a17a30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting loop on datasets:  ['DataHTA_2018']\n",
      "Local time : 2023-11-16 16:10:47.925752\n",
      "requirements: \n",
      "Initializing DataFrame for DataHTA_2018 chain len =  699\n",
      "All histos booked !\n"
     ]
    }
   ],
   "source": [
    "t0 = datetime.now()\n",
    "print(\"starting loop on datasets: \",[d.label for d in datasets])\n",
    "print(\"Local time :\", t0)\n",
    "print(\"requirements: \"+cut)\n",
    "\n",
    "d = datasets[0]\n",
    "s = datasets[0]\n",
    "\n",
    "if 'Data' in s.label : sampleflag = 0\n",
    "else: sampleflag = 1\n",
    "c_ = cut\n",
    "        \n",
    "if nfiles_max > len(samples[d.label][s.label]['strings']): \n",
    "    nfiles = len(samples[d.label][s.label]['strings'])\n",
    "    for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "        samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "    chain = samples[d.label][s.label]['strings']\n",
    "else: \n",
    "    nfiles = nfiles_max\n",
    "    # for i, string in enumerate(samples[d.label][s.label]['strings']): \n",
    "    #     samples[d.label][s.label]['strings'][i] = string.replace(\"root://cms-xrd-global.cern.ch/\", \"root://stormgf2.pi.infn.it/\")\n",
    "    chain = samples[d.label][s.label]['strings'][:nfiles]\n",
    "print(\"Initializing DataFrame for \"+ s.label +\" chain len = \", len(chain))\n",
    "if len(chain)==1: print(chain)\n",
    "if distributed ==True:\n",
    "    df = RDataFrame(\"Events\", chain, npartitions=nmaxpartition, \n",
    "                    daskclient=client, monitor_label = \"main\" )\n",
    "else:\n",
    "    df = RDataFrame(\"Events\", chain)\n",
    "\n",
    "df_ismc         = df.Define(\"isMC\", \"isMC(\"+str(sampleflag)+\")\")\n",
    "df_year         = df_ismc.Define(\"year\", str(s.year))\n",
    "df_hemveto      = df_year.Define(\"HEMVeto\", \"hemveto(Jet_eta, Jet_phi, Electron_eta, Electron_phi)\")\n",
    "df_wnom         = df_hemveto.Define('w_nominal', '1')\n",
    "df_presel       = preselection(df_wnom)\n",
    "\n",
    "s_cut = cut_string(cut)\n",
    "h = bookhisto(df_presel, regions_def, var, s_cut)\n",
    "\n",
    "# if not distributed:\n",
    "#     df_presel.Report().Print()\n",
    "\n",
    "print(\"All histos booked !\")\n",
    "savehisto(d, h, regions_def, var, s_cut)\n",
    "print(d.label + \" finished!\")\n",
    "t1 = datetime.now()\n",
    "print(\"Job finished in: \", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573b747-9a5a-4501-b084-481b10d418ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = ROOT.TFile.Open(repohisto+s.label+\".root\")\n",
    "for a in file.GetListOfKeys(): print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3606a5b-e3ce-491d-a86a-6c02431ca435",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_def.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269963fc-638b-4a19-8c8d-af26bad6e37f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = \"NoCut\"\n",
    "var = \"MET_pt\"\n",
    "for reg in regions_def.keys():\n",
    "    hist = file.Get(var+\"_\"+reg+\"_\")\n",
    "    print(reg, hist.Integral())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f91eb-e0db-49b0-a71d-256c56220b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Singularity kernel",
   "language": "python",
   "name": "singularity-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
